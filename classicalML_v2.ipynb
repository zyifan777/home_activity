{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical ML Training and Results V2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle \n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file and put into one matrix \n",
    "# same process of v1\n",
    "def readData(filename,x1):\n",
    "    f = open(\"data/\"+filename,'r')\n",
    "    for row in f:\n",
    "        data = [int(p) for p in row.split(',')]\n",
    "        x1.append(np.array(data))\n",
    "    return \n",
    "\n",
    "x = []\n",
    "readData(\"getOutBed.csv\",x)\n",
    "readData(\"getOnBed.csv\",x)\n",
    "readData(\"layOnBed.csv\",x)\n",
    "readData(\"sitOnBed.csv\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X an numpy array and initialize Y \n",
    "x = np.array(x)\n",
    "y = np.array([1]*120+[0]*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = []\n",
    "for r in x:\n",
    "    s1, s2, s3 = r[:20000], r[20000:40000], r[40000:]\n",
    "    temp1 = [stats.mean(s1), stats.median(s1), stats.variance(s1), max(s1), min(s1)]\n",
    "    temp2 = [stats.mean(s2), stats.median(s2), stats.variance(s2), max(s2), min(s2)]\n",
    "    temp3 = [stats.mean(s3), stats.median(s3), stats.variance(s3), max(s3), min(s3)]\n",
    "#     print temp1\n",
    "    x_feature.append(np.array(temp1+temp2+temp3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = np.array(x_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BALANCING SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 120+np.random.choice(360,240,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "x_lst = x_feature.tolist()\n",
    "print len(x_lst[0])\n",
    "for i in sorted(index, reverse=True):\n",
    "    del x_lst[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature = np.array(x_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 15)\n"
     ]
    }
   ],
   "source": [
    "print x_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<type 'numpy.ndarray'>, <type 'numpy.ndarray'>)\n",
      "(192, 15, 192, 48, 15, 48)\n"
     ]
    }
   ],
   "source": [
    "# shuffle X and Y correspondingly \n",
    "X, Y = shuffle(x_feature, y, random_state = 34)\n",
    "offset = int(len(X)*0.8)\n",
    "X_train, Y_train = X[:offset], Y[:offset]\n",
    "X_test, Y_test = X[offset:], Y[offset:]\n",
    "print (type(X_train), type(Y_train))\n",
    "print (len(X_train), len(X_train[0]), len(Y_train), len(X_test), len(X_test[0]), len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training of SVM \n",
    "clf = svm.SVC(gamma='scale',max_iter=5000, verbose=True)\n",
    "clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833333333333\n"
     ]
    }
   ],
   "source": [
    "# Verification of SVM \n",
    "results = clf.predict(X_test)\n",
    "correct = 0\n",
    "for i in xrange(len(results)):\n",
    "    if results[i] == Y_test[i]:\n",
    "        correct+=1\n",
    "print (correct/float(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAUSSIAN NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training \n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 0 0 0 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "results_nb = clf_nb.predict(X_test)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854166666667\n"
     ]
    }
   ],
   "source": [
    "# verification\n",
    "c_nb = 0 \n",
    "for i in xrange(len(results_nb)):\n",
    "    if results_nb[i] == Y_test[i]:\n",
    "        c_nb += 1\n",
    "print (c_nb/float(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8200            0.47s\n",
      "         2           0.7261            0.26s\n",
      "         3           0.6216            0.19s\n",
      "         4           0.5702            0.15s\n",
      "         5           0.5509            0.13s\n",
      "         6           0.5293            0.11s\n",
      "         7           0.4962            0.10s\n",
      "         8           0.4585            0.09s\n",
      "         9           0.4131            0.09s\n",
      "        10           0.3689            0.08s\n",
      "        20           0.2152            0.05s\n",
      "        30           0.1278            0.03s\n",
      "        40           0.0984            0.03s\n",
      "        50           0.0705            0.02s\n",
      "        60           0.0553            0.01s\n",
      "        70           0.0410            0.01s\n",
      "        80           0.0335            0.01s\n",
      "        90           0.0267            0.00s\n",
      "       100           0.0200            0.00s\n"
     ]
    }
   ],
   "source": [
    "clf_gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0, verbose = True).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958333333333334"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verification\n",
    "clf_gbc.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
